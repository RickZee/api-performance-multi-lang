spring:
  application:
    name: stream-processor-spring
  
  config:
    import: optional:file:./filters.yml
    activate:
      on-profile: default
  
  kafka:
    streams:
      application-id: ${SPRING_KAFKA_STREAMS_APPLICATION_ID:event-stream-processor-v1}
      bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
      source-topic: ${SPRING_KAFKA_STREAMS_SOURCE_TOPIC:raw-event-headers}
      properties:
        # Confluent Cloud SASL_SSL configuration
        security.protocol: ${KAFKA_SECURITY_PROTOCOL:SASL_SSL}
        sasl.mechanism: ${KAFKA_SASL_MECHANISM:PLAIN}
        sasl.jaas.config: >
          org.apache.kafka.common.security.plain.PlainLoginModule required
          username="${KAFKA_API_KEY:}" password="${KAFKA_API_SECRET:}";
        # Exactly-once semantics
        processing.guarantee: exactly_once_v2
        # Consumer settings
        default.key.serde: org.apache.kafka.common.serialization.Serdes$StringSerde
        default.value.serde: com.example.streamprocessor.serde.EventHeaderSerde
        # Producer settings
        acks: all
        retries: 2147483647
        max.in.flight.requests.per.connection: 5
        enable.idempotence: true
        # State store settings
        state.dir: /tmp/kafka-streams
        # Replication factor for internal topics (Confluent Cloud uses 3 by default)
        # Note: These are for internal Kafka Streams topics, not the source topic
        replication.factor: 3
        min.insync.replicas: 2
        # Consumer settings for Confluent Cloud
        consumer.auto.offset.reset: earliest

management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics
  endpoint:
    health:
      show-details: always
  health:
    kafka:
      enabled: true
    kafkastreams:
      enabled: true

logging:
  level:
    com.example.streamprocessor: INFO
    org.apache.kafka: INFO
    org.apache.kafka.streams: INFO
    org.springframework.kafka: INFO
    org.springframework.kafka.streams: INFO

app:
  display-timezone: ${DISPLAY_TIMEZONE:America/New_York}

# Metadata Service configuration for dynamic filter loading
metadata:
  service:
    enabled: ${METADATA_SERVICE_ENABLED:false}
    url: ${METADATA_SERVICE_URL:http://localhost:8080}
    schema:
      version: ${METADATA_SERVICE_SCHEMA_VERSION:v1}
    poll:
      interval: ${METADATA_SERVICE_POLL_INTERVAL:30000}
    timeout-seconds: ${METADATA_SERVICE_TIMEOUT_SECONDS:5}
    max-retries: ${METADATA_SERVICE_MAX_RETRIES:3}
