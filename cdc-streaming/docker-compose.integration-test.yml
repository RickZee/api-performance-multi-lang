version: '3.8'

services:
  # Redpanda - Kafka-compatible message broker (default for local mode)
  # Can be overridden with Confluent Cloud via environment variables
  redpanda:
    image: docker.redpanda.com/redpandadata/redpanda:latest
    container_name: int-test-redpanda
    command:
      - redpanda
      - start
      - --smp 1
      - --memory 1G
      - --overprovisioned
      - --kafka-addr
      - internal://0.0.0.0:9092,external://0.0.0.0:29092
      - --advertise-kafka-addr
      - internal://redpanda:9092,external://127.0.0.1:29092
      - --pandaproxy-addr
      - internal://0.0.0.0:8082,external://0.0.0.0:28082
      - --advertise-pandaproxy-addr
      - internal://redpanda:8082,external://127.0.0.1:28082
      - --schema-registry-addr
      - internal://0.0.0.0:8081,external://0.0.0.0:28081
      - --rpc-addr
      - redpanda:33145
      - --advertise-rpc-addr
      - redpanda:33145
      - --default-log-level=info
    ports:
      - "29092:9092" # Kafka API (internal port 9092, external 29092)
      - "29644:9644"  # Admin API
      - "28081:8081"  # Schema Registry
      - "28082:8082"  # Pandaproxy
    volumes:
      - redpanda-data:/var/lib/redpanda/data
    healthcheck:
      test: ["CMD-SHELL", "rpk cluster health | grep -q healthy"]
      interval: 5s
      timeout: 3s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
        reservations:
          memory: 512M
          cpus: '0.5'

  # Redpanda Console - Web UI for topic management
  redpanda-console:
    image: docker.redpanda.com/redpandadata/console:latest
    container_name: int-test-redpanda-console
    environment:
      CONFIG_FILEPATH: /tmp/config.yml
      KAFKA_BROKERS: redpanda:9092
      KAFKA_SCHEMAREGISTRY_ENABLED: "true"
      KAFKA_SCHEMAREGISTRY_URLS: http://redpanda:8081
    ports:
      - "8086:8080"  # Redpanda Console UI
    depends_on:
      redpanda:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'

  # PostgreSQL database for Metadata Service
  # Default to local postgres, can use Aurora via USE_AURORA=true
  postgres:
    image: postgres:15-alpine
    container_name: int-test-postgres
    environment:
      POSTGRES_DB: metadata_service
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      retries: 10
    volumes:
      - postgres-data:/var/lib/postgresql/data
    # Default to starting postgres (local mode)
    # Can be skipped if USE_AURORA=true is set

  # Mock Confluent Flink API (for deployment testing)
  mock-confluent-api:
    build:
      context: ./test-infrastructure/mock-confluent-api
      dockerfile: Dockerfile
    container_name: int-test-mock-confluent-api
    ports:
      - "8082:8082"
    environment:
      MOCK_API_PORT: 8082

  # Metadata Service (uses mock Confluent API)
  metadata-service:
    build:
      context: ../metadata-service-java
      dockerfile: Dockerfile
    container_name: int-test-metadata-service
    depends_on:
      postgres:
        condition: service_healthy
        required: false  # Not required if using Aurora
      mock-confluent-api:
        condition: service_started
      redpanda:
        condition: service_healthy
        required: false  # Not required if using Confluent Cloud
    ports:
      - "8080:8080"
    environment:
      GIT_REPOSITORY: file:///app/test-data
      CONFLUENT_CLOUD_API_ENDPOINT: http://mock-confluent-api:8082
      CONFLUENT_CLOUD_API_KEY: test-key
      CONFLUENT_CLOUD_API_SECRET: test-secret
      # Database configuration - default to local postgres, use Aurora if USE_AURORA=true
      DATABASE_URL: ${DATABASE_URL:-jdbc:postgresql://postgres:5432/metadata_service}
      DATABASE_USERNAME: ${DATABASE_USERNAME:-postgres}
      DATABASE_PASSWORD: ${DATABASE_PASSWORD:-postgres}
      # Kafka configuration - default to Redpanda (local), can override with Confluent Cloud
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS:-redpanda:9092}
      KAFKA_API_KEY: ${KAFKA_API_KEY:-}
      KAFKA_API_SECRET: ${KAFKA_API_SECRET:-}
    volumes:
      - ../data:/app/test-data:ro
    healthcheck:
      test: curl -f http://localhost:8080/api/v1/health || exit 1
      interval: 5s
      retries: 10

  # Stream Processor Spring Boot
  stream-processor:
    build:
      context: ./stream-processor-spring
      dockerfile: Dockerfile
    container_name: int-test-stream-processor
    depends_on:
      redpanda:
        condition: service_healthy
        required: false  # Not required if using Confluent Cloud
    ports:
      - "8083:8080"
    environment:
      # Kafka configuration - default to Redpanda (local), can override with Confluent Cloud
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS:-redpanda:9092}
      KAFKA_API_KEY: ${KAFKA_API_KEY:-}
      KAFKA_API_SECRET: ${KAFKA_API_SECRET:-}
      # Default to PLAINTEXT for local Redpanda, use SASL_SSL for Confluent Cloud
      # If KAFKA_API_KEY is set, default to SASL_SSL, otherwise PLAINTEXT
      KAFKA_SECURITY_PROTOCOL: ${KAFKA_SECURITY_PROTOCOL:-PLAINTEXT}
      KAFKA_SASL_MECHANISM: ${KAFKA_SASL_MECHANISM:-PLAIN}
      SPRING_KAFKA_STREAMS_SOURCE_TOPIC: raw-event-headers
      FILTER_CONFIG_PATH: /app/config/filters.json
      # Enable Metadata Service integration for dynamic filter loading
      METADATA_SERVICE_ENABLED: "true"
      METADATA_SERVICE_URL: http://metadata-service:8080
      METADATA_SERVICE_SCHEMA_VERSION: v1
      METADATA_SERVICE_POLL_INTERVAL: 30000
      # Replication settings for local single-node Redpanda
      KAFKA_REPLICATION_FACTOR: ${KAFKA_REPLICATION_FACTOR:-1}
      KAFKA_MIN_INSYNC_REPLICAS: ${KAFKA_MIN_INSYNC_REPLICAS:-1}
    volumes:
      - ./config:/app/config:ro
      - ./stream-processor-spring/src/main/resources/filters.yml:/app/filters.yml:ro
    healthcheck:
      test: curl -f http://localhost:8080/actuator/health || exit 1
      interval: 5s
      retries: 10

  # V2 Stream Processor (for breaking schema changes)
  stream-processor-v2:
    build:
      context: ./stream-processor-spring
      dockerfile: Dockerfile
    container_name: int-test-stream-processor-v2
    profiles: ["v2"]
    depends_on:
      metadata-service:
        condition: service_healthy
      redpanda:
        condition: service_healthy
        required: false  # Not required if using Confluent Cloud
    ports:
      - "8084:8080"
    environment:
      # Kafka configuration - default to Redpanda (local), can override with Confluent Cloud
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS:-redpanda:9092}
      KAFKA_API_KEY: ${KAFKA_API_KEY:-}
      KAFKA_API_SECRET: ${KAFKA_API_SECRET:-}
      # Default to PLAINTEXT for local Redpanda, use SASL_SSL for Confluent Cloud
      # If KAFKA_API_KEY is set, default to SASL_SSL, otherwise PLAINTEXT
      KAFKA_SECURITY_PROTOCOL: ${KAFKA_SECURITY_PROTOCOL:-PLAINTEXT}
      KAFKA_SASL_MECHANISM: ${KAFKA_SASL_MECHANISM:-PLAIN}
      SPRING_KAFKA_STREAMS_SOURCE_TOPIC: raw-event-headers-v2
      SPRING_KAFKA_STREAMS_APPLICATION_ID: event-stream-processor-v2
      FILTER_CONFIG_PATH: /app/config/filters-v2.json
      FILTER_VERSION: v2
      OUTPUT_TOPIC_SUFFIX: -v2
      # Enable Metadata Service integration for V2
      METADATA_SERVICE_ENABLED: "true"
      METADATA_SERVICE_URL: http://metadata-service:8080
      METADATA_SERVICE_SCHEMA_VERSION: v2
      METADATA_SERVICE_POLL_INTERVAL: 30000
      # Replication settings for local single-node Redpanda
      KAFKA_REPLICATION_FACTOR: ${KAFKA_REPLICATION_FACTOR:-1}
      KAFKA_MIN_INSYNC_REPLICAS: ${KAFKA_MIN_INSYNC_REPLICAS:-1}
    volumes:
      - ./config:/app/config:ro
      - ./stream-processor-spring/src/main/resources/filters.yml:/app/filters.yml:ro
    healthcheck:
      test: curl -f http://localhost:8080/actuator/health || exit 1
      interval: 5s
      retries: 10

  # Consumers (Spring variant - reads from -spring topics)
  car-consumer:
    build:
      context: ./consumers-confluent/car-consumer
    container_name: int-test-car-consumer
    depends_on:
      redpanda:
        condition: service_healthy
        required: false  # Not required if using Confluent Cloud
    environment:
      # Kafka configuration - default to Redpanda (local), can override with Confluent Cloud
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS:-redpanda:9092}
      KAFKA_API_KEY: ${KAFKA_API_KEY:-}
      KAFKA_API_SECRET: ${KAFKA_API_SECRET:-}
      KAFKA_TOPIC: filtered-car-created-events-spring
      CONSUMER_GROUP_ID: int-test-car-consumer-group

  loan-consumer:
    build:
      context: ./consumers-confluent/loan-consumer
    container_name: int-test-loan-consumer
    depends_on:
      redpanda:
        condition: service_healthy
        required: false  # Not required if using Confluent Cloud
    environment:
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS:-redpanda:9092}
      KAFKA_API_KEY: ${KAFKA_API_KEY:-}
      KAFKA_API_SECRET: ${KAFKA_API_SECRET:-}
      KAFKA_TOPIC: filtered-loan-created-events-spring
      CONSUMER_GROUP_ID: int-test-loan-consumer-group

  loan-payment-consumer:
    build:
      context: ./consumers-confluent/loan-payment-consumer
    container_name: int-test-loan-payment-consumer
    depends_on:
      redpanda:
        condition: service_healthy
        required: false  # Not required if using Confluent Cloud
    environment:
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS:-redpanda:9092}
      KAFKA_API_KEY: ${KAFKA_API_KEY:-}
      KAFKA_API_SECRET: ${KAFKA_API_SECRET:-}
      KAFKA_TOPIC: filtered-loan-payment-submitted-events-spring
      CONSUMER_GROUP_ID: int-test-loan-payment-consumer-group

  service-consumer:
    build:
      context: ./consumers-confluent/service-consumer
    container_name: int-test-service-consumer
    depends_on:
      redpanda:
        condition: service_healthy
        required: false  # Not required if using Confluent Cloud
    environment:
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS:-redpanda:9092}
      KAFKA_API_KEY: ${KAFKA_API_KEY:-}
      KAFKA_API_SECRET: ${KAFKA_API_SECRET:-}
      KAFKA_TOPIC: filtered-service-events-spring
      CONSUMER_GROUP_ID: int-test-service-consumer-group

  # V2 Consumers (for breaking schema changes)
  car-consumer-v2:
    build:
      context: ./consumers-confluent/car-consumer
    container_name: int-test-car-consumer-v2
    profiles: ["v2"]
    depends_on:
      redpanda:
        condition: service_healthy
        required: false  # Not required if using Confluent Cloud
    environment:
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS:-redpanda:9092}
      KAFKA_API_KEY: ${KAFKA_API_KEY:-}
      KAFKA_API_SECRET: ${KAFKA_API_SECRET:-}
      KAFKA_TOPIC: filtered-car-created-events-v2-spring
      CONSUMER_GROUP_ID: int-test-car-consumer-group-v2

  loan-consumer-v2:
    build:
      context: ./consumers-confluent/loan-consumer
    container_name: int-test-loan-consumer-v2
    profiles: ["v2"]
    depends_on:
      redpanda:
        condition: service_healthy
        required: false  # Not required if using Confluent Cloud
    environment:
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS:-redpanda:9092}
      KAFKA_API_KEY: ${KAFKA_API_KEY:-}
      KAFKA_API_SECRET: ${KAFKA_API_SECRET:-}
      KAFKA_TOPIC: filtered-loan-created-events-v2-spring
      CONSUMER_GROUP_ID: int-test-loan-consumer-group-v2

  loan-payment-consumer-v2:
    build:
      context: ./consumers-confluent/loan-payment-consumer
    container_name: int-test-loan-payment-consumer-v2
    profiles: ["v2"]
    depends_on:
      redpanda:
        condition: service_healthy
        required: false  # Not required if using Confluent Cloud
    environment:
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS:-redpanda:9092}
      KAFKA_API_KEY: ${KAFKA_API_KEY:-}
      KAFKA_API_SECRET: ${KAFKA_API_SECRET:-}
      KAFKA_TOPIC: filtered-loan-payment-submitted-events-v2-spring
      CONSUMER_GROUP_ID: int-test-loan-payment-consumer-group-v2

  service-consumer-v2:
    build:
      context: ./consumers-confluent/service-consumer
    container_name: int-test-service-consumer-v2
    profiles: ["v2"]
    depends_on:
      redpanda:
        condition: service_healthy
        required: false  # Not required if using Confluent Cloud
    environment:
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS:-redpanda:9092}
      KAFKA_API_KEY: ${KAFKA_API_KEY:-}
      KAFKA_API_SECRET: ${KAFKA_API_SECRET:-}
      KAFKA_TOPIC: filtered-service-events-v2-spring
      CONSUMER_GROUP_ID: int-test-service-consumer-group-v2

  # Note: Topics are created in Redpanda (local mode) using rpk CLI
  # Or in Confluent Cloud (--confluent-cloud flag) using Confluent CLI
  # See run-all-integration-tests.sh for topic creation

volumes:
  postgres-data:
  redpanda-data:

