version: '3.8'

services:
  # Note: Using Confluent Cloud for Kafka, Schema Registry, and Kafka Connect
  # Local Zookeeper and Kafka services have been removed
  # Schema Registry, Kafka Connect, and Control Center are managed in Confluent Cloud

  # Flink JobManager
  # Note: For production, use Confluent Cloud Flink. This local Flink is for development/testing only.
  flink-jobmanager:
    image: flink:1.18.0-scala_2.12
    container_name: cdc-flink-jobmanager
    hostname: flink-jobmanager
    ports:
      - "8082:8081"
    command: jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        jobmanager.memory.process.size: 1600m
        taskmanager.numberOfTaskSlots: 2
        parallelism.default: 2
        state.backend: filesystem
        state.checkpoints.dir: file:///opt/flink/checkpoints
        state.savepoints.dir: file:///opt/flink/savepoints
    volumes:
      - ./flink-jobs:/opt/flink/jobs
      - ./config/flink-conf.yaml:/opt/flink/conf/flink-conf.yaml:ro
      - flink-checkpoints:/opt/flink/checkpoints
      - flink-savepoints:/opt/flink/savepoints
    networks:
      - cdc-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/overview"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Flink TaskManager
  flink-taskmanager:
    image: flink:1.18.0-scala_2.12
    container_name: cdc-flink-taskmanager
    hostname: flink-taskmanager
    depends_on:
      flink-jobmanager:
        condition: service_healthy
    command: taskmanager
    scale: 1
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.numberOfTaskSlots: 2
        parallelism.default: 2
        state.backend: filesystem
        state.checkpoints.dir: file:///opt/flink/checkpoints
        state.savepoints.dir: file:///opt/flink/savepoints
    volumes:
      - ./flink-jobs:/opt/flink/jobs
      - ./config/flink-conf.yaml:/opt/flink/conf/flink-conf.yaml:ro
      - flink-checkpoints:/opt/flink/checkpoints
      - flink-savepoints:/opt/flink/savepoints
    networks:
      - cdc-network

  # Spring Boot Stream Processor
  # Alternative to Flink for event filtering and routing
  stream-processor:
    build:
      context: ./stream-processor-spring
      dockerfile: Dockerfile
    container_name: cdc-stream-processor
    hostname: stream-processor
    environment:
      # Set KAFKA_BOOTSTRAP_SERVERS to your Confluent Cloud bootstrap servers
      # Example: pkc-xxxxx.us-east-1.aws.confluent.cloud:9092
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS}
      KAFKA_API_KEY: ${KAFKA_API_KEY:-}
      KAFKA_API_SECRET: ${KAFKA_API_SECRET:-}
      KAFKA_SECURITY_PROTOCOL: ${KAFKA_SECURITY_PROTOCOL:-SASL_SSL}
      KAFKA_SASL_MECHANISM: ${KAFKA_SASL_MECHANISM:-PLAIN}
      # Spring Kafka Streams configuration
      SPRING_KAFKA_STREAMS_SOURCE_TOPIC: raw-event-headers
    ports:
      - "8083:8080"  # Actuator health endpoint
    networks:
      - cdc-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/actuator/health"]
      interval: 30s
      timeout: 3s
      start_period: 40s
      retries: 3

  # Loan Consumer
  loan-consumer:
    build:
      context: ./consumers/loan-consumer
      dockerfile: Dockerfile
    container_name: cdc-loan-consumer
    hostname: loan-consumer
    environment:
      # Set KAFKA_BOOTSTRAP_SERVERS to your Confluent Cloud bootstrap servers
      # Example: pkc-xxxxx.us-east-1.aws.confluent.cloud:9092
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS}
      KAFKA_TOPIC: filtered-loan-created-events
      KAFKA_API_KEY: ${KAFKA_API_KEY:-}
      KAFKA_API_SECRET: ${KAFKA_API_SECRET:-}
      CONSUMER_GROUP_ID: loan-consumer-group
    networks:
      - cdc-network
    restart: unless-stopped

  # Loan Payment Consumer
  loan-payment-consumer:
    build:
      context: ./consumers/loan-payment-consumer
      dockerfile: Dockerfile
    container_name: cdc-loan-payment-consumer
    hostname: loan-payment-consumer
    environment:
      # Set KAFKA_BOOTSTRAP_SERVERS to your Confluent Cloud bootstrap servers
      # Example: pkc-xxxxx.us-east-1.aws.confluent.cloud:9092
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS}
      KAFKA_TOPIC: filtered-loan-payment-submitted-events
      KAFKA_API_KEY: ${KAFKA_API_KEY:-}
      KAFKA_API_SECRET: ${KAFKA_API_SECRET:-}
      CONSUMER_GROUP_ID: loan-payment-consumer-group
    networks:
      - cdc-network
    restart: unless-stopped

  # Service Consumer
  service-consumer:
    build:
      context: ./consumers/service-consumer
      dockerfile: Dockerfile
    container_name: cdc-service-consumer
    hostname: service-consumer
    environment:
      # Set KAFKA_BOOTSTRAP_SERVERS to your Confluent Cloud bootstrap servers
      # Example: pkc-xxxxx.us-east-1.aws.confluent.cloud:9092
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS}
      KAFKA_TOPIC: filtered-service-events
      KAFKA_API_KEY: ${KAFKA_API_KEY:-}
      KAFKA_API_SECRET: ${KAFKA_API_SECRET:-}
      CONSUMER_GROUP_ID: service-consumer-group
    networks:
      - cdc-network
    restart: unless-stopped

  # Car Consumer
  car-consumer:
    build:
      context: ./consumers/car-consumer
      dockerfile: Dockerfile
    container_name: cdc-car-consumer
    hostname: car-consumer
    environment:
      # Set KAFKA_BOOTSTRAP_SERVERS to your Confluent Cloud bootstrap servers
      # Example: pkc-xxxxx.us-east-1.aws.confluent.cloud:9092
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS}
      KAFKA_TOPIC: filtered-car-created-events
      KAFKA_API_KEY: ${KAFKA_API_KEY:-}
      KAFKA_API_SECRET: ${KAFKA_API_SECRET:-}
      CONSUMER_GROUP_ID: car-consumer-group
    networks:
      - cdc-network
    restart: unless-stopped

volumes:
  flink-checkpoints:
  flink-savepoints:

networks:
  cdc-network:
    driver: bridge
    external: false
  car_network:
    external: true

