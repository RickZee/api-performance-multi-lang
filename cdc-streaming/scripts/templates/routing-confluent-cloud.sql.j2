-- Flink SQL Job for Event Filtering and Routing (Confluent Cloud)
-- This file is AUTO-GENERATED from filters.yaml
-- DO NOT EDIT MANUALLY - Changes will be overwritten
-- Generated by: generate-flink-sql.py
-- Source: filters.yaml
-- Target: Confluent Cloud Flink

BEGIN STATEMENT SET;

-- ============================================================================
-- Source Table: Raw Business Events from Kafka
-- Note: Table name must match topic name exactly in Confluent Cloud
-- ============================================================================
CREATE TABLE `raw-business-events` (
    `eventHeader` ROW<
        `uuid` STRING,
        `eventName` STRING,
        `createdDate` BIGINT,
        `savedDate` BIGINT,
        `eventType` STRING
    >,
    `eventBody` ROW<
        `entities` ARRAY<ROW<
            `entityType` STRING,
            `entityId` STRING,
            `updatedAttributes` MAP<STRING, STRING>
        >>
    >,
    `sourceMetadata` ROW<
        `table` STRING,
        `operation` STRING,
        `timestamp` BIGINT
    >,
    `eventtime` AS TO_TIMESTAMP_LTZ(`eventHeader`.`createdDate`, 3),
    WATERMARK FOR `eventtime` AS `eventtime` - INTERVAL '5' SECOND
) WITH (
    'connector' = 'confluent',
    'value.format' = 'avro-registry',
    'value.avro.schema.registry.url' = '{{ schema_registry_url }}',
    'value.avro.schema.registry.basic-auth.credentials-source' = 'USER_INFO',
    'value.avro.schema.registry.basic-auth.user-info' = '{{ schema_registry_api_key }}:{{ schema_registry_api_secret }}',
    'scan.startup.mode' = 'earliest-offset'
);

{% for filter in filters %}
-- ============================================================================
-- Sink Table: {{ filter.name }}
-- Note: Table name must match topic name exactly in Confluent Cloud
-- ============================================================================
CREATE TABLE `{{ filter.outputTopic }}` (
    `eventHeader` ROW<
        `uuid` STRING,
        `eventName` STRING,
        `createdDate` BIGINT,
        `savedDate` BIGINT,
        `eventType` STRING
    >,
    `eventBody` ROW<
        `entities` ARRAY<ROW<
            `entityType` STRING,
            `entityId` STRING,
            `updatedAttributes` MAP<STRING, STRING>
        >>
    >,
    `sourceMetadata` ROW<
        `table` STRING,
        `operation` STRING,
        `timestamp` BIGINT
    >,
    `filterMetadata` ROW<
        `filterId` STRING,
        `consumerId` STRING,
        `filteredAt` BIGINT
    >
) WITH (
    'connector' = 'confluent',
    'value.format' = 'avro-registry',
    'value.avro.schema.registry.url' = '{{ schema_registry_url }}',
    'value.avro.schema.registry.basic-auth.credentials-source' = 'USER_INFO',
    'value.avro.schema.registry.basic-auth.user-info' = '{{ schema_registry_api_key }}:{{ schema_registry_api_secret }}'
);

{% endfor %}
-- ============================================================================
-- Filtering and Routing Queries
-- ============================================================================

{% for filter in filters %}
-- {{ filter.name }}
-- {% if filter.description %}{{ filter.description }}{% endif %}
INSERT INTO `{{ filter.outputTopic }}`
SELECT 
    `eventHeader`,
    `eventBody`,
    `sourceMetadata`,
    ROW(
        '{{ filter.id }}',
        '{{ filter.consumerId }}',
        UNIX_TIMESTAMP() * 1000
    ) AS `filterMetadata`
FROM `raw-business-events`
{% if filter.conditions %}
WHERE {{ generator.generate_where_clause(filter) }}
{% endif %};

{% endfor %}

END;

