-- Flink SQL Statements for Event Filtering and Routing (Confluent Cloud)
-- This file is AUTO-GENERATED from filters.yaml
-- DO NOT EDIT MANUALLY - Changes will be overwritten
-- Generated by: generate-flink-sql.py
-- Source: filters.yaml
-- Target: Confluent Cloud Flink
-- 
-- DEPLOYMENT NOTE: Deploy statements in order:
-- 1. Source table (raw-business-events)
-- 2. Sink tables (filtered-*-events)
-- 3. INSERT statements (one per filter)

-- ============================================================================
-- Step 1: Create Source Table
-- ============================================================================
-- Source Table: Raw Business Events from Kafka (Debezium CDC format)
-- Note: Table name must match topic name exactly in Confluent Cloud
-- This table reads the raw Debezium output format
CREATE TABLE `raw-business-events` (
    `id` STRING,
    `car_id` STRING,
    `entity_type` STRING,
    `created_at` STRING,
    `updated_at` STRING,
    `data` STRING,
    `__op` STRING,
    `__table` STRING,
    `__ts_ms` BIGINT
) WITH (
    'connector' = 'confluent',
    'value.format' = 'json-registry',
    'scan.startup.mode' = 'earliest-offset'
);

-- ============================================================================
-- Step 2: Create Sink Tables
-- ============================================================================
{% for filter in filters %}
-- Sink Table: {{ filter.name }}
-- Note: Table name must match topic name exactly in Confluent Cloud
-- Solution 1C: Keep Debezium format (flat structure, no nested ROWs)
-- Note: Excluding __ts_ms to avoid Flink eventtime inference
CREATE TABLE `{{ filter.outputTopic }}` (
    `id` STRING,
    `car_id` STRING,
    `entity_type` STRING,
    `created_at` STRING,
    `updated_at` STRING,
    `data` STRING,
    `__op` STRING,
    `__table` STRING
) WITH (
    'connector' = 'confluent',
    'value.format' = 'json-registry'
);

{% endfor %}
-- ============================================================================
-- Step 3: Deploy INSERT Statements (one per filter)
-- ============================================================================
-- Deploy each INSERT statement separately as individual Flink statements
-- Each INSERT statement should be deployed as a separate statement

{% for filter in filters %}
-- ============================================================================
-- INSERT Statement: {{ filter.name }}
-- Statement Name: {{ filter.id }}-insert
-- {% if filter.description %}{{ filter.description }}{% endif %}
-- Solution 1C: Simple SELECT with filtering (no transformation)
-- ============================================================================
INSERT INTO `{{ filter.outputTopic }}`
SELECT 
    `id`,
    `car_id`,
    `entity_type`,
    `created_at`,
    `updated_at`,
    `data`,
    `__op`,
    `__table`
FROM `raw-business-events`
{% if filter.conditions %}
WHERE {{ generator.generate_where_clause(filter) }}
{% endif %};

{% endfor %}

