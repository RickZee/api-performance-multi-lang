# Terraform Variables Example
# Copy this file to terraform.tfvars and customize for your environment
# terraform.tfvars is in .gitignore and should not be committed

# Project configuration
project_name = "producer-api"
aws_region   = "us-east-1"
log_level    = "info"

# Database configuration
# Option 1: Full connection string (takes precedence if provided)
# database_url = "postgresql://user:password@host:5432/dbname"

# Option 2: Aurora endpoint with separate credentials
# aurora_endpoint   = "your-aurora-endpoint.cluster-xxxxx.us-east-1.rds.amazonaws.com"
# database_name     = "car_entities"
# database_user     = "postgres"
# database_password = "your-secure-password"

# VPC configuration (optional, required if enable_vpc = true)
# enable_vpc = false
# vpc_id     = "vpc-xxxxx"
# subnet_ids = ["subnet-xxxxx", "subnet-yyyyy"]

# Database creation (optional)
# enable_database = false

# Aurora PostgreSQL (recommended for Confluent Cloud integration)
# enable_aurora = true
# aurora_instance_class = "db.t3.medium"  # Minimal provisioned instance

# Public Internet Access for Confluent Cloud (Option 1)
# =====================================================
# When to use: For testing or if RDS is publicly accessible
# Requirements: RDS instance must have "Publicly accessible" enabled
# Security: Use confluent_cloud_cidrs to restrict access to Confluent Cloud IPs only
# Connector: Use Postgres CDC Source V2 (Debezium) in Confluent Cloud
#
# aurora_publicly_accessible = true
#
# Option A: Restricted access (RECOMMENDED)
# Restrict security group to Confluent Cloud IP ranges only
# Get IP ranges using: terraform/scripts/get-confluent-cloud-ips.sh
# Or check: https://docs.confluent.io/cloud/current/networking/ip-ranges.html
# confluent_cloud_cidrs = [
#   "13.57.0.0/16",  # Example - replace with actual Confluent Cloud egress IPs
#   "52.0.0.0/16"    # Example - replace with actual Confluent Cloud egress IPs
# ]
#
# Option B: Unrestricted access (NOT RECOMMENDED for production)
# Allows access from any IP address - use with caution
# confluent_cloud_cidrs = []  # Empty means use aurora_allowed_cidr_blocks
# aurora_allowed_cidr_blocks = ["0.0.0.0/0"]  # Allows all IPs
#
# Note: For production, prefer AWS PrivateLink (Option 2) over public access
# See: terraform/PUBLIC_ACCESS_SETUP.md for complete setup guide

# Aurora DSQL Configuration (Alternative to regular Aurora)
# ==========================================================
# Aurora DSQL uses IAM authentication instead of password-based authentication
# This provides better security with temporary credentials
#
# enable_aurora_dsql = true
# aurora_dsql_endpoint = "your-dsql-cluster.cluster-xxxxx.us-east-1.rds.amazonaws.com"
# aurora_dsql_port = 5432  # Default PostgreSQL port
# iam_database_user = "your-iam-db-user"  # IAM database user (not regular DB user)
# aurora_dsql_cluster_resource_id = "cluster-xxxxx"  # Cluster resource ID for IAM permissions
#
# Prerequisites:
# 1. Create an Aurora DSQL cluster (outside of this Terraform configuration)
# 2. Create an IAM database user in the DSQL cluster
# 3. Grant necessary database permissions to the IAM user
# 4. The Lambda function will automatically get IAM permissions for rds-db:connect
#
# Note: When enable_aurora_dsql is true, the Lambda will use IAM authentication
#       instead of password-based authentication. The DSQL endpoint and IAM user
#       must be configured for this to work.

# Lambda configuration
# lambda_memory_size = 512
# lambda_timeout     = 30

# DSQL Load Test Lambda (optional - for load testing only)
# =========================================================
# Standalone Lambda function for DSQL load testing (separate from producer API)
# This Lambda is designed for high-throughput load testing with parallel invocations
#
# enable_dsql_load_test_lambda = false  # Set to true to enable
# dsql_load_test_lambda_memory_size = 1024  # Memory in MB (default: 1024 for load tests)
# dsql_load_test_lambda_timeout = 900  # Timeout in seconds (default: 900 = 15 minutes)
# dsql_load_test_lambda_reserved_concurrency = null  # null = no limit, or set to 1000 for load tests
#
# Note: This Lambda requires:
# 1. Aurora DSQL cluster (enable_aurora_dsql_cluster = true) OR
# 2. Manual DSQL configuration (aurora_dsql_endpoint, iam_database_user, etc.)
# 3. Lambda deployment package uploaded to S3 at: dsql-load-test/lambda-deployment.zip
#
# After deployment, update load-test/dsql-load-test/config.json with the function name

# Aurora Auto-Stop Email Notifications
# =====================================
# Optional: Receive email notifications when Aurora cluster is automatically stopped
# due to inactivity. Leave empty or omit to disable email notifications.
#
# aurora_auto_stop_admin_email = "admin@example.com"
#
# Important: After setting this and running terraform apply, AWS SNS will send
# a confirmation email to the provided address. You must click the confirmation
# link in that email before notifications will be sent. This is a one-time setup.
#
# The notification email will include:
# - Cluster ID
# - Timestamp when stopped
# - Reason (inactivity duration)
# - AWS region

# S3 bucket name (optional, will be auto-generated if not provided)
# s3_bucket_name = ""

# Terraform State Backend (S3)
# enable_terraform_state_backend = true  # Create S3 bucket and DynamoDB table for state
# terraform_state_bucket_name = ""       # Auto-generated if empty
# terraform_state_dynamodb_table_name = ""  # Auto-generated if empty

# Tags
# tags = {
#   Environment = "dev"
#   Project     = "api-performance"
# }
